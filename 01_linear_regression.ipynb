{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linjär Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enkel modell för linjär regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-5-05c9b09a79ad>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-05c9b09a79ad>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    Image(filename='C:\\Users\\usr000617/10_01.png', width=500)\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "Image(filename='C:\\Users\\usr000617/10_01.png', width=500) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"The Housing dataset\" - ett standard dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Från: [https://archive.ics.uci.edu/ml/datasets/Housing](https://archive.ics.uci.edu/ml/datasets/Housing)\n",
    "\n",
    "Datatyper:\n",
    "    \n",
    "<pre>\n",
    "1. CRIM      per capita crime rate by town\n",
    "2. ZN        proportion of residential land zoned for lots over \n",
    "                 25,000 sq.ft.\n",
    "3. INDUS     proportion of non-retail business acres per town\n",
    "4. CHAS      Charles River dummy variable (= 1 if tract bounds \n",
    "                 river; 0 otherwise)\n",
    "5. NOX       nitric oxides concentration (parts per 10 million)\n",
    "6. RM        average number of rooms per dwelling\n",
    "7. AGE       proportion of owner-occupied units built prior to 1940\n",
    "8. DIS       weighted distances to five Boston employment centres\n",
    "9. RAD       index of accessibility to radial highways\n",
    "10. TAX      full-value property-tax rate per $10,000\n",
    "11. PTRATIO  pupil-teacher ratio by town\n",
    "12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks \n",
    "                 by town\n",
    "13. LSTAT    % lower status of the population\n",
    "14. MEDV     Median value of owner-occupied homes in $1000's\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File databases/housing.data does not exist: 'databases/housing.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b91122537fc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m df = pd.read_csv('databases/housing.data',\n\u001b[0m\u001b[0;32m      4\u001b[0m                  \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  sep='\\s+')\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File databases/housing.data does not exist: 'databases/housing.data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('databases/housing.data',\n",
    "                 header=None,\n",
    "                 sep='\\s+')\n",
    "\n",
    "df.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', \n",
    "              'NOX', 'RM', 'AGE', 'DIS', 'RAD', \n",
    "              'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisera datasetet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "Skapa en scatterplot matrix som visualiserar förhållandena mellan\n",
    "olika features parvis.\n",
    "\n",
    "Det som visas här är \"Pearson's r\".  Den är definierad som kovariansen mellan två features (x och y) dividerad med standardavvikelsen för x resp y, \n",
    "\n",
    "$$r = \\frac{\\sigma_{xy}}{\\sigma_x  \\sigma_y}$$.  \n",
    "\n",
    "Se https://en.wikipedia.org/wiki/Pearson_correlation_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5948d669d983>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'LSTAT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'INDUS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NOX'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MEDV'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "cols = ['LSTAT', 'INDUS', 'NOX', 'RM', 'MEDV']\n",
    "\n",
    "sns.pairplot(df[cols], height=2.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "För att kvantifiera detta, skapa en korrelationsmatris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "cm = np.corrcoef(df[cols].values.T)\n",
    "sns.set(font_scale=1.5)\n",
    "hm = sns.heatmap(cm,\n",
    "                 cbar=True,\n",
    "                 annot=True,\n",
    "                 square=True,\n",
    "                 fmt='.2f',\n",
    "                 annot_kws={'size': 15},\n",
    "                 yticklabels=cols,\n",
    "                 xticklabels=cols)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset plot settings modified by seaborn to default\n",
    "sns.reset_orig()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lös regressionsmodellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Lösning med \"gradient descent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionGD(object):\n",
    "\n",
    "    def __init__(self, eta=0.001, n_iter=20):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.cost_ = []\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            output = self.net_input(X)\n",
    "            errors = (y - output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.net_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['RM']].values\n",
    "y = df['MEDV'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skala variablerna till -1 <= x <= 1 (approximativt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X_std = sc_x.fit_transform(X)\n",
    "y_std = sc_y.fit_transform(y[:, np.newaxis]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegressionGD()\n",
    "lr.fit(X_std, y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, lr.n_iter+1), lr.cost_)\n",
    "plt.ylabel('SSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_regplot(X, y, model):\n",
    "    plt.scatter(X, y, c='lightblue')\n",
    "    plt.plot(X, model.predict(X), color='red', linewidth=2)    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regplot(X_std, y_std, lr)\n",
    "plt.xlabel('Average number of rooms [RM] (standardized)')\n",
    "plt.ylabel('Price in $1000\\'s [MEDV] (standardized)')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Slope: %.3f' % lr.w_[1])\n",
    "print('Intercept: %.3f' % lr.w_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gå tillbaka till de \"oskalade\" variablerna genom att göra en invers transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rooms_std = sc_x.transform(np.array([[5.0]]))\n",
    "price_std = lr.predict(num_rooms_std)\n",
    "print(\"Price in $1000's: %.3f\" % sc_y.inverse_transform(price_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lösning med scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr = LinearRegression()\n",
    "slr.fit(X, y)\n",
    "y_pred = slr.predict(X)\n",
    "print('Slope: %.3f' % slr.coef_[0])\n",
    "print('Intercept: %.3f' % slr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regplot(X, y, slr)\n",
    "plt.xlabel('Average number of rooms [RM]')\n",
    "plt.ylabel('Price in $1000\\'s [MEDV]')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# En robustare modell - RANSAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linjära regressionsmodeller kan påverkas ganska mycket av \"uteliggare\".  Det finns\n",
    "algoritmer för att testa vilka punkter som kan anses vara uteliggare, men det är en\n",
    "bedömningsfråga.\n",
    "\n",
    "En robustare metod är att använda RANSAC: RANdom SAmple Consensus.\n",
    "\n",
    "1. Börja med att slumpmässigt välja ut ett antal punkter som \"inneliggare\", och anpassa en modell efter dessa.\n",
    "2. Testa alla andra punkter mot denna modell, och lägg till de punkter som ligger inom ett givet intervall från modellen.\n",
    "3. Anpassa en ny modell med både de gamla och de nya punkterna inkluderade.\n",
    "4. Estimera felet mellan nya modellen och alla \"inneliggare\".\n",
    "5. Om felet är mindre än ett specificerat värde eller om antalet maximala iterationer har överskridits: klart!  Annars gå tillbaka till punkt 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "ransac = RANSACRegressor(LinearRegression(), \n",
    "                         max_trials=100, \n",
    "                         min_samples=50, \n",
    "                         loss='absolute_loss', \n",
    "                         residual_threshold=5.0, \n",
    "                         random_state=0)\n",
    "\n",
    "\n",
    "ransac.fit(X, y)\n",
    "inlier_mask = ransac.inlier_mask_\n",
    "outlier_mask = np.logical_not(inlier_mask)\n",
    "\n",
    "line_X = np.arange(3, 10, 1)\n",
    "line_y_ransac = ransac.predict(line_X[:, np.newaxis])\n",
    "plt.scatter(X[inlier_mask], y[inlier_mask],\n",
    "            c='blue', marker='o', label='Inliers')\n",
    "plt.scatter(X[outlier_mask], y[outlier_mask],\n",
    "            c='lightgreen', marker='s', label='Outliers')\n",
    "plt.plot(line_X, line_y_ransac, color='red')   \n",
    "plt.xlabel('Average number of rooms [RM]')\n",
    "plt.ylabel('Price in $1000\\'s [MEDV]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Slope: %.3f' % ransac.estimator_.coef_[0])\n",
    "print('Intercept: %.3f' % ransac.estimator_.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utvärdera modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use all variables as inputs\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df['MEDV'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr = LinearRegression()\n",
    "\n",
    "slr.fit(X_train, y_train)\n",
    "y_train_pred = slr.predict(X_train)\n",
    "y_test_pred = slr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressionen är nu multi-dimensionell, och vi kan inte bara plotta hyper-planet.\n",
    "Istället plottar vi residualen, dvs skillnaden mellan verkligt värde och predikterat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train_pred,  y_train_pred - y_train,\n",
    "            c='blue', marker='o', label='Training data')\n",
    "plt.scatter(y_test_pred,  y_test_pred - y_test,\n",
    "            c='lightgreen', marker='s', label='Test data')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper left')\n",
    "plt.hlines(y=0, xmin=-10, xmax=50, lw=2, color='red')\n",
    "plt.xlim([-10, 50])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^2$ här är \"coefficient of determination\".  Det är ett mått på hur bra en modell predikterar datat.  \n",
    "\n",
    "Definitionen på $R^2$ är\n",
    "\n",
    "$$R^2 = 1 - \\frac{SS_{\\mathrm{pred}}}{SS_{\\mathrm{tot}}}$$\n",
    "\n",
    "där $SS$ är \"sum of squares\" för det \"sanna värdet\" resp prediktionen:\n",
    "$$SS_\\mathrm{tot} = \\sum_i (y_i - \\overline{y_i})^2$$\n",
    "och\n",
    "$$SS_\\mathrm{pred} = \\sum_i (y_i - y_{{\\mathrm pred},i})^2$$\n",
    "(Notera att $SS_\\mathrm{tot}$ i princip är samma som variansen (skiljer en faktor).)\n",
    "\n",
    "$R^2$ är alltså hur stor del av variationen i utvariabeln (prediktionen) som förklaras av modellen.  För träningssetet ligger alltid $R^2$ mellan 0 och 1 (där då \"1\" indikerar att prediktionen passar perfekt med datat; detta motsvarar att MSE, dvs kvadratsummefelet, är 0).  För testsetet kan, i sämsta fall, $R^2$ bli negativ.\n",
    "\n",
    "Notera att vi ovan använde Pearson's r på *indatat*, dvs $X$.  Här har vi beräknat $R^2$ på *utdatat*, dvs $y$. Om man beräknar Pearson's r på utdatat så är det samma sak som $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "        mean_squared_error(y_train, y_train_pred),\n",
    "        mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train, y_train_pred),\n",
    "        r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularisering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidigare tittade vi på regularisering när vi lade till en summa\n",
    "över kvadraten på koefficienterna: w^2\n",
    "\n",
    "Detta kallas även \"ridge regression\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# alpha is similar to our parameter lambda\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_train_pred = ridge.predict(X_train)\n",
    "y_test_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "        mean_squared_error(y_train, y_train_pred),\n",
    "        mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train, y_train_pred),\n",
    "        r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan även titta på regularisering med en summa över absolutbeloppet av koefficienterna: | w |.  Detta är LASSO, Least Absolute Shrinking and Selection Operator.\n",
    "\n",
    "LASSO straffar inte enskilda stora koefficienter lika hårt.  Istället tvingas fler koefficienter att bli små.\n",
    "Ibland blir vissa koefficienter lika med noll. LASSO funkar då som en \"feature-väljare\", dvs den pekar ut de\n",
    "features som spelar minst roll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_train_pred = lasso.predict(X_train)\n",
    "y_test_pred = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "        mean_squared_error(y_train, y_train_pred),\n",
    "        mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train, y_train_pred),\n",
    "        r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "För att bestämma det optimala värdet på alpha/lambda kan vi använda oss av validerings-setet eller kors-validering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linjär regressionsmodel med polynom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi börjar med en enkel model med lite \"dummy data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([258.0, 270.0, 294.0, \n",
    "              320.0, 342.0, 368.0, \n",
    "              396.0, 446.0, 480.0, 586.0])[:, np.newaxis]\n",
    "\n",
    "y = np.array([236.4, 234.4, 252.8, \n",
    "              298.6, 314.2, 342.2, \n",
    "              360.8, 368.0, 391.2,\n",
    "              390.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addera andra-grads-polynom för våra variabler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "lr = LinearRegression()\n",
    "pr = LinearRegression()\n",
    "quadratic = PolynomialFeatures(degree=2)\n",
    "X_quad = quadratic.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit linear features\n",
    "lr.fit(X, y)\n",
    "X_fit = np.arange(250, 600, 10)[:, np.newaxis]\n",
    "y_lin_fit = lr.predict(X_fit)\n",
    "\n",
    "# fit quadratic features\n",
    "pr.fit(X_quad, y)\n",
    "y_quad_fit = pr.predict(quadratic.fit_transform(X_fit))\n",
    "\n",
    "# plot results\n",
    "plt.scatter(X, y, label='training points')\n",
    "plt.plot(X_fit, y_lin_fit, label='linear fit', linestyle='--')\n",
    "plt.plot(X_fit, y_quad_fit, label='quadratic fit')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lin_pred = lr.predict(X)\n",
    "y_quad_pred = pr.predict(X_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training MSE linear: %.3f, quadratic: %.3f' % (\n",
    "        mean_squared_error(y, y_lin_pred),\n",
    "        mean_squared_error(y, y_quad_pred)))\n",
    "print('Training R^2 linear: %.3f, quadratic: %.3f' % (\n",
    "        r2_score(y, y_lin_pred),\n",
    "        r2_score(y, y_quad_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Icke-linjär modellering av \"Housing Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['LSTAT']].values\n",
    "y = df['MEDV'].values\n",
    "\n",
    "regr = LinearRegression()\n",
    "\n",
    "# create quadratic features\n",
    "quadratic = PolynomialFeatures(degree=2)\n",
    "cubic = PolynomialFeatures(degree=3)\n",
    "X_quad = quadratic.fit_transform(X)\n",
    "X_cubic = cubic.fit_transform(X)\n",
    "\n",
    "# fit features\n",
    "X_fit = np.arange(X.min(), X.max(), 1)[:, np.newaxis]\n",
    "\n",
    "# Linear fit\n",
    "regr = regr.fit(X, y)\n",
    "y_lin_fit = regr.predict(X_fit)\n",
    "linear_r2 = r2_score(y, regr.predict(X))\n",
    "\n",
    "# Quadratic fit\n",
    "regr = regr.fit(X_quad, y)\n",
    "y_quad_fit = regr.predict(quadratic.fit_transform(X_fit))\n",
    "quadratic_r2 = r2_score(y, regr.predict(X_quad))\n",
    "\n",
    "# Cubic fit\n",
    "regr = regr.fit(X_cubic, y)\n",
    "y_cubic_fit = regr.predict(cubic.fit_transform(X_fit))\n",
    "cubic_r2 = r2_score(y, regr.predict(X_cubic))\n",
    "\n",
    "\n",
    "# plot results\n",
    "plt.scatter(X, y, label='training points', color='lightgray')\n",
    "\n",
    "plt.plot(X_fit, y_lin_fit, \n",
    "         label='linear (d=1), $R^2=%.2f$' % linear_r2, \n",
    "         color='blue', \n",
    "         lw=2, \n",
    "         linestyle=':')\n",
    "\n",
    "plt.plot(X_fit, y_quad_fit, \n",
    "         label='quadratic (d=2), $R^2=%.2f$' % quadratic_r2,\n",
    "         color='red', \n",
    "         lw=2,\n",
    "         linestyle='-')\n",
    "\n",
    "plt.plot(X_fit, y_cubic_fit, \n",
    "         label='cubic (d=3), $R^2=%.2f$' % cubic_r2,\n",
    "         color='green', \n",
    "         lw=2, \n",
    "         linestyle='--')\n",
    "\n",
    "plt.xlabel('% lower status of the population [LSTAT]')\n",
    "plt.ylabel('Price in $1000\\'s [MEDV]')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andra transformationer än polynom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['LSTAT']].values\n",
    "y = df['MEDV'].values\n",
    "\n",
    "# transform features\n",
    "X_log = np.log(X)\n",
    "y_sqrt = np.sqrt(y)\n",
    "\n",
    "# fit features\n",
    "X_fit = np.arange(X_log.min()-1, X_log.max()+1, 1)[:, np.newaxis]\n",
    "\n",
    "regr = regr.fit(X_log, y_sqrt)\n",
    "y_lin_fit = regr.predict(X_fit)\n",
    "linear_r2 = r2_score(y_sqrt, regr.predict(X_log))\n",
    "\n",
    "# plot results\n",
    "plt.scatter(X_log, y_sqrt, label='training points', color='lightgray')\n",
    "\n",
    "plt.plot(X_fit, y_lin_fit, \n",
    "         label='linear (d=1), $R^2=%.2f$' % linear_r2, \n",
    "         color='blue', \n",
    "         lw=2)\n",
    "\n",
    "plt.xlabel('log(% lower status of the population [LSTAT])')\n",
    "plt.ylabel('$\\sqrt{Price \\; in \\; \\$1000\\'s [MEDV]}$')\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
